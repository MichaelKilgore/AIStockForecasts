configs:
  sagemaker-simple-daily-1-with-time-features:
    notes: 'todo - run in progress'
    features:
      - open
      - close
      - high
      - low
      - trade_count
      - volume
      - vwap
      - day_of_week
      - day_of_month
      - month
      - year
    train_start: "2020-01-01"
    train_end: "2024-01-01"
    val_end: "2025-01-01"
    test_end: "2026-01-01"
    max_lookback_period: 60
    max_prediction_length: 2
    accelerator: 'gpu'
    local_accelerator: 'mps'
    devices: 1
    num_workers: 4
    batch_size: 16384
    hidden_size: 8
    attention_head_size: 1
    dropout: 0.1
    hidden_continuous_size: 4
    lstm_layers: 1
    learning_rate: 0.0001
    max_epochs: 50
    time_frame_unit: 'Day'
    time_frame_amount: 1
    reduce_on_plateau_patience: 5
    _instance_type: 'ml.g4dn.xlarge'
    _instance_count: 1
    _run_time: '2 hours 54 minutes'
    _loss: 'QuantileLoss(0.3, 0.5, 0.7)'
  m1-simple-daily-1-with-time-features:
    notes: 'same config as sagemaker-daily-1-with-time-features but different batch_size and num_workers'
    features:
      - open
      - close
      - high
      - low
      - trade_count
      - volume
      - vwap
      - day_of_week
      - day_of_month
      - month
      - year
    train_start: "2020-01-01"
    train_end: "2024-01-01"
    val_end: "2025-01-01"
    test_end: "2026-01-01"
    max_lookback_period: 60
    max_prediction_length: 2
    accelerator: 'mps'
    devices: 1
    num_workers: 4
    batch_size: 2048
    hidden_size: 8
    attention_head_size: 1
    dropout: 0.1
    hidden_continuous_size: 4
    lstm_layers: 1
    learning_rate: 0.0001
    max_epochs: 50
    time_frame_unit: 'Day'
    time_frame_amount: 1
    reduce_on_plateau_patience: 5
    _best_val_loss: 3.3939
    _loss: 'QuantileLoss(0.3, 0.5, 0.7)'
  m1-simple-daily-1-with-time-features-fine-tuned:
    notes: 'finetuning results of m1-simple-daily-1-with-time-features. Only ran for 18 epochs. It did not improve val loss at all. Model performance on test dataset also degraded slightly most likely because of the val loss'
    fine_tuning_model_id: 'm1-simple-daily-1-with-time-features'
    features:
      - open
      - close
      - high
      - low
      - trade_count
      - volume
      - vwap
      - day_of_week
      - day_of_month
      - month
      - year
    train_start: "2020-01-01"
    train_end: "2024-01-01"
    val_end: "2025-01-01"
    test_end: "2026-01-01"
    max_lookback_period: 60
    max_prediction_length: 2
    accelerator: 'mps'
    devices: 1
    num_workers: 4
    batch_size: 2048
    hidden_size: 8
    attention_head_size: 1
    dropout: 0.1
    hidden_continuous_size: 4
    lstm_layers: 1
    learning_rate: 0.0001
    max_epochs: 50
    time_frame_unit: 'Day'
    time_frame_amount: 1
    reduce_on_plateau_patience: 5
    _loss: 'QuantileLoss(0.3, 0.5, 0.7)'
    _best_val_loss: 3.537207
    _best_train_loss: 2.646061
  m1-medium-daily-1-with-time-features-and-faster-learning-rate:
    notes: 'upgrading the hidden_size, attention_head_size, hidden_continuous_size, and learning rate'
    features:
      - open
      - close
      - high
      - low
      - trade_count
      - volume
      - vwap
      - day_of_week
      - day_of_month
      - month
      - year
    train_start: "2020-01-01"
    train_end: "2024-01-01"
    val_end: "2025-01-01"
    test_end: "2026-01-01"
    max_lookback_period: 60
    max_prediction_length: 2
    accelerator: 'mps'
    devices: 1
    num_workers: 4
    batch_size: 2048
    hidden_size: 16
    attention_head_size: 2
    dropout: 0.1
    hidden_continuous_size: 8
    lstm_layers: 1
    learning_rate: 0.001
    max_epochs: 50
    time_frame_unit: 'Day'
    time_frame_amount: 1
    best_val_loss: 2.8900
    train_loss: 2.580746
    reduce_on_plateau_patience: 5
    feature_importance_notes: 'encoder variable importance labels open as 87% importance, every other feature is less than 3%. decoder variable importance gave day_of_week 80%'
  m1-medium-high-daily-1-with-time-features-and-faster-learning-rate:
    notes: 'upgrading the hidden_size, attention_head_size, hidden_continuous_size, and learning rate, performance test results overall were really bad.'
    features:
      - open
      - close
      - high
      - low
      - trade_count
      - volume
      - vwap
      - day_of_week
      - day_of_month
      - month
      - year
    train_start: "2020-01-01"
    train_end: "2024-01-01"
    val_end: "2025-01-01"
    test_end: "2026-01-01"
    max_lookback_period: 60
    max_prediction_length: 2
    accelerator: 'mps'
    devices: 1
    num_workers: 4
    batch_size: 2048
    hidden_size: 32
    attention_head_size: 4
    dropout: 0.1
    hidden_continuous_size: 16
    lstm_layers: 1
    learning_rate: 0.001
    max_epochs: 50
    time_frame_unit: 'Day'
    time_frame_amount: 1
    reduce_on_plateau_patience: 5
    trainable_params: '69.6k'
    _train_loss: 2.587998
    _best_val_loss: 2.878758
    _best_epoch: 2
    _performance_test_1:
      _test_strategy: SimpleXDaysAheadBuying
      _test_range: '2025-01-01 - 2026-01-01'
      _interval_days: 1
      _num_stocks_purchased: 50
      _capital_gains_tax: 0.35
      _uncertainty_multiplier: 0.2
      _compound_money: True
      _dont_buy_negative_stocks: True
      _money_made: 28698.52734375
      _annual_sharpe: 0.7390310856262804
  m1-medium-with-less-features:
    notes: ''
    features:
      - open
      - day_of_week
      - day_of_month
      - month
      - year
    train_start: "2020-01-01"
    train_end: "2024-01-01"
    val_end: "2025-01-01"
    test_end: "2026-01-01"
    max_lookback_period: 60
    max_prediction_length: 2
    accelerator: 'mps'
    devices: 1
    num_workers: 4
    batch_size: 2048
    hidden_size: 16
    attention_head_size: 2
    dropout: 0.1
    hidden_continuous_size: 8
    lstm_layers: 1
    learning_rate: 0.001
    max_epochs: 50
    time_frame_unit: 'Day'
    time_frame_amount: 1
    reduce_on_plateau_patience: 5
    train_loss: 2.562474
    best_val_loss: 2.9491 
  m1-medium-with-less-features-and-longer-lookback:
    notes: 'trying longer lookback to see if that had any impact on val loss. Did not seem to... also performance test results were bad overall, the bottoom one shown was the very best of the combinations.'
    features:
      - open
      - day_of_week
      - day_of_month
      - month
      - year
    train_start: "2020-01-01"
    train_end: "2024-01-01"
    val_end: "2025-01-01"
    test_end: "2026-01-01"
    max_lookback_period: 180
    max_prediction_length: 2
    accelerator: 'mps'
    devices: 1
    num_workers: 4
    batch_size: 2048
    hidden_size: 16
    attention_head_size: 2
    dropout: 0.1
    hidden_continuous_size: 8
    lstm_layers: 1
    learning_rate: 0.001
    max_epochs: 50
    time_frame_unit: 'Day'
    time_frame_amount: 1
    reduce_on_plateau_patience: 5
    _best_epoch: 5
    _best_val_loss: 3.2674
    _performance_test_1:
      _test_strategy: SimpleXDaysAheadBuying
      _test_range: '2025-01-01 - 2026-01-01'
      _interval_days: 1
      _num_stocks_purchased: 10
      _capital_gains_tax: 0.35
      _uncertainty_multiplier: 0.1
      _compound_money: True
      _dont_buy_negative_stocks: True
      _money_made: 32646.369140625
      _annual_sharpe: 1.2086021735066093
  m1-medium-with-less-features-and-earnings-calendar-features:
    notes: 'Performance test below was the best test by far but pretty much every other variation of num stocks and interval days the model did bad.'
    features:
      - open
      - day_of_week
      - day_of_month
      - month
      - year
      - surprise
      - is_earnings_day
    train_start: "2020-01-01"
    train_end: "2024-01-01"
    val_end: "2025-01-01"
    test_end: "2026-01-01"
    max_lookback_period: 60
    max_prediction_length: 2
    accelerator: 'mps'
    devices: 1
    num_workers: 4
    batch_size: 2048
    hidden_size: 16
    attention_head_size: 2
    dropout: 0.1
    hidden_continuous_size: 8
    lstm_layers: 1
    learning_rate: 0.001
    max_epochs: 50
    time_frame_unit: 'Day'
    time_frame_amount: 1
    reduce_on_plateau_patience: 5
    _best_val_loss: 2.874714
    _train_loss: 2.584665
    _best_epoch: 5
    _performance_test_1:
      _test_strategy: SimpleXDaysAheadBuying
      _test_range: '2025-01-01 - 2026-01-01'
      _interval_days: 2
      _num_stocks_purchased: 10
      _capital_gains_tax: 0.35
      _uncertainty_multiplier: 0.1
      _compound_money: True
      _dont_buy_negative_stocks: True
      _money_made: 31369.30078125
      _annual_sharpe: 1.2182196707273427
  m1-medium-with-less-features-and-earnings-calendar-features-and-trade-volume:
    notes: 'performance test below was the best result by far but over all results were not that amazing.'
    features:
      - open
      - day_of_week
      - day_of_month
      - month
      - year
      - surprise
      - is_earnings_day
      - trade_count
      - volume
    train_start: "2020-01-01"
    train_end: "2024-01-01"
    val_end: "2025-01-01"
    test_end: "2026-01-01"
    max_lookback_period: 60
    max_prediction_length: 2
    accelerator: 'mps'
    devices: 1
    num_workers: 4
    batch_size: 2048
    hidden_size: 16
    attention_head_size: 2
    dropout: 0.1
    hidden_continuous_size: 8
    lstm_layers: 1
    learning_rate: 0.001
    max_epochs: 50
    time_frame_unit: 'day'
    time_frame_amount: 1
    reduce_on_plateau_patience: 5
    _best_epoch: 4
    _best_val_loss: 2.8769
    _train_loss: 2.609082
    _performance_test_1:
      _test_strategy: SimpleXDaysAheadBuying
      _test_range: '2025-01-01 - 2026-01-01'
      _interval_days: 2
      _num_stocks_purchased: 25
      _capital_gains_tax: 0.35
      _uncertainty_multiplier: 0.3
      _compound_money: True
      _dont_buy_negative_stocks: True
      _money_made: 30073.98828125
      _annual_sharpe: 1.3219341667768554
  m1-medium-high-with-less-features-and-earnings-calendar-features:
    notes: 'despite the val loss indicating the model is clearly overfitted the sharpe ratio on almost all interval 2 tests was good. The performance test below was the best result.'
    _favorite: True
    features:
      - open
      - day_of_week
      - day_of_month
      - month
      - year
      - surprise
      - is_earnings_day
    train_start: "2020-01-01"
    train_end: "2024-01-01"
    val_end: "2025-01-01"
    test_end: "2026-01-01"
    max_lookback_period: 60
    max_prediction_length: 2
    accelerator: 'mps'
    devices: 1
    num_workers: 4
    batch_size: 2048
    hidden_size: 32
    attention_head_size: 4
    dropout: 0.1
    hidden_continuous_size: 16
    lstm_layers: 1
    learning_rate: 0.001
    max_epochs: 50
    time_frame_unit: 'Day'
    time_frame_amount: 1
    reduce_on_plateau_patience: 5
    total_params: '59.3 K'
    _best_val_loss: 3.830369
    _train_loss: 2.143075
    preferred_trading_strategy: '_performance_test_1'
    _performance_test_1:
      _test_strategy: SimpleXDaysAheadBuying
      _test_range: '2025-01-01 - 2026-01-01'
      _interval_days: 2
      _num_stocks_purchased: 50
      _capital_gains_tax: 0.35
      _uncertainty_multiplier: 0.3
      _compound_money: True
      _dont_buy_negative_stocks: True
      _money_made: 32534.86328125
      _annual_sharpe: 2.2221535285706975
  m1-medium-with-2-lstm-layers:
    notes: ''
    features:
      - open
      - day_of_week
      - day_of_month
      - month
      - year
      - surprise
      - is_earnings_day
    train_start: "2020-01-01"
    train_end: "2024-01-01"
    val_end: "2025-01-01"
    test_end: "2026-01-01"
    max_lookback_period: 60
    max_prediction_length: 5
    accelerator: 'mps'
    devices: 1
    num_workers: 4
    batch_size: 2048
    hidden_size: 16
    attention_head_size: 4
    dropout: 0.1
    hidden_continuous_size: 8
    lstm_layers: 2
    learning_rate: 0.001
    max_epochs: 50
    time_frame_unit: 'Day'
    time_frame_amount: 1
    reduce_on_plateau_patience: 5
    total_params: '59.3 K'
    _best_val_loss: 4.175
    _train_loss: 3.505094
  m1-medium-with-weighted-quantile-loss:
    notes: 'Trying with weighted quantile loss. Results were very bad. None of the trading strategies reached even 30k profit.'
    features:
      - open
      - day_of_week
      - day_of_month
      - month
      - year
      - surprise
      - is_earnings_day
      - trade_count
      - volume
    train_start: "2020-01-01"
    train_end: "2024-01-01"
    val_end: "2025-01-01"
    test_end: "2026-01-01"
    max_lookback_period: 60
    max_prediction_length: 2
    accelerator: 'mps'
    devices: 1
    num_workers: 4
    batch_size: 2048
    hidden_size: 16
    attention_head_size: 2
    dropout: 0.1
    hidden_continuous_size: 8
    lstm_layers: 1
    learning_rate: 0.001
    max_epochs: 50
    time_frame_unit: 'Day'
    time_frame_amount: 1
    reduce_on_plateau_patience: 5
    loss: 'WeightedQuantileLoss'
    _best_val_loss: 0.0145
  m1-medium-new-quantiles:
    notes: 'performance test below was the best result by far but over all results were not that amazing.'
    features:
      - open
      - day_of_week
      - day_of_month
      - month
      - year
      - surprise
      - is_earnings_day
      - trade_count
      - volume
    train_start: "2020-01-01"
    train_end: "2024-01-01"
    val_end: "2025-01-01"
    test_end: "2026-01-01"
    max_lookback_period: 60
    max_prediction_length: 7
    accelerator: 'mps'
    devices: 1
    num_workers: 4
    batch_size: 2048
    hidden_size: 16
    attention_head_size: 2
    dropout: 0.1
    hidden_continuous_size: 8
    lstm_layers: 1
    learning_rate: 0.001
    max_epochs: 50
    time_frame_unit: 'Day'
    time_frame_amount: 1
    reduce_on_plateau_patience: 5
    quantiles:
      - 0.1
      - 0.5
      - 0.9
  m1-medium-with-less-features-and-earnings-calendar-features-and-tuning-with-optimal:
    notes: 'val loss did not improve at all with the new learning rate.'
    fine_tuning_model_id: 'm1-medium-with-less-features-and-earnings-calendar-features'
    features:
      - open
      - day_of_week
      - day_of_month
      - month
      - year
      - surprise
      - is_earnings_day
    train_start: "2020-01-01"
    train_end: "2024-01-01"
    val_end: "2025-01-01"
    test_end: "2026-01-01"
    max_lookback_period: 60
    max_prediction_length: 2
    accelerator: 'mps'
    devices: 1
    num_workers: 4
    batch_size: 2048
    hidden_size: 16
    attention_head_size: 2
    dropout: 0.1
    hidden_continuous_size: 8
    lstm_layers: 1
    learning_rate: 6.60693448007596e-05
    max_epochs: 50
    time_frame_unit: 'Day'
    time_frame_amount: 1
    reduce_on_plateau_patience: 5
    _best_val_loss: 2.8791
    _train_loss: 2.555740
  m1-optimal-hyper-params:
    notes: 'Ran find_optimal_hyperparameters for these features and lookback window / prediction length and these are the optimal params.'
    features:
      - open
      - day_of_week
      - day_of_month
      - month
      - year
      - surprise
      - is_earnings_day
    train_start: "2020-01-01"
    train_end: "2024-01-01"
    val_end: "2025-01-01"
    test_end: "2026-01-01"
    max_lookback_period: 60
    max_prediction_length: 2
    accelerator: 'mps'
    devices: 1
    num_workers: 4
    batch_size: 2048
    hidden_size: 17
    attention_head_size: 4
    dropout: 0.16814472086063664
    hidden_continuous_size: 14
    lstm_layers: 1
    learning_rate: 0.0018197008586099835
    max_epochs: 50
    time_frame_unit: 'Day'
    time_frame_amount: 1
    reduce_on_plateau_patience: 5
    gradient_clip_val: 0.4467135116262659
  ubuntu-optimal-hyper-params:
    notes: 'run on ubuntu with rtx 4070 ti'
    features:
      - open
      - day_of_week
      - day_of_month
      - month
      - year
      - surprise
      - is_earnings_day
    train_start: "2020-01-01"
    train_end: "2024-01-01"
    val_end: "2025-01-01"
    test_end: "2026-01-01"
    max_lookback_period: 60
    max_prediction_length: 2
    accelerator: 'cuda'
    devices: 1
    num_workers: 4
    batch_size: 2048
    hidden_size: 17
    attention_head_size: 4
    dropout: 0.16814472086063664
    hidden_continuous_size: 14
    lstm_layers: 1
    learning_rate: 0.0018197008586099835
    max_epochs: 50
    time_frame_unit: 'Day'
    time_frame_amount: 1
    reduce_on_plateau_patience: 5
    gradient_clip_val: 0.4467135116262659
    _best_val_loss: 2.8601
  ubuntu-optimal-hyper-params-with-cpu:
    notes: 'was definitely slower than with gpu'
    features:
      - open
      - day_of_week
      - day_of_month
      - month
      - year
      - surprise
      - is_earnings_day
    train_start: "2020-01-01"
    train_end: "2024-01-01"
    val_end: "2025-01-01"
    test_end: "2026-01-01"
    max_lookback_period: 60
    max_prediction_length: 2
    accelerator: 'cpu'
    devices: 1
    num_workers: 4
    batch_size: 2048
    hidden_size: 17
    attention_head_size: 4
    dropout: 0.16814472086063664
    hidden_continuous_size: 14
    lstm_layers: 1
    learning_rate: 0.0018197008586099835
    max_epochs: 50
    time_frame_unit: 'Day'
    time_frame_amount: 1
    reduce_on_plateau_patience: 5
    gradient_clip_val: 0.4467135116262659
  ubuntu-optimal-hyper-params-with-larger-batch-size:
    notes: ''
    features:
      - open
      - day_of_week
      - day_of_month
      - month
      - year
      - surprise
      - is_earnings_day
    train_start: "2020-01-01"
    train_end: "2024-01-01"
    val_end: "2025-01-01"
    test_end: "2026-01-01"
    max_lookback_period: 60
    max_prediction_length: 2
    accelerator: 'cuda'
    devices: 1
    num_workers: 4
    batch_size: 4096
    hidden_size: 17
    attention_head_size: 4
    dropout: 0.16814472086063664
    hidden_continuous_size: 14
    lstm_layers: 1
    learning_rate: 0.0018197008586099835
    max_epochs: 50
    time_frame_unit: 'Day'
    time_frame_amount: 1
    reduce_on_plateau_patience: 5
    gradient_clip_val: 0.4467135116262659
  ubuntu-with-sandp500-feature:
    notes: ''
    features:
      - open
      - day_of_week
      - day_of_month
      - month
      - year
      - surprise
      - is_earnings_day
      - sandp500open
    train_start: "2020-08-01"
    train_end: "2024-01-01"
    val_end: "2025-01-01"
    test_end: "2026-01-01"
    max_lookback_period: 60
    max_prediction_length: 2
    accelerator: 'cuda'
    devices: 1
    num_workers: 4
    batch_size: 4096
    hidden_size: 17
    attention_head_size: 4
    dropout: 0.16814472086063664
    hidden_continuous_size: 14
    lstm_layers: 1
    learning_rate: 0.0018197008586099835
    max_epochs: 50
    time_frame_unit: 'Day'
    time_frame_amount: 1
    reduce_on_plateau_patience: 5
    gradient_clip_val: 0.4467135116262659
    _best_val_loss: 2.9449
  ubuntu-with-log-return-target:
    notes: ''
    features:
      - open_log_return
      - day_of_week
      - day_of_month
      - month
      - year
      - surprise
      - is_earnings_day
    target: 'open_log_return'
    target_normalizer: 'None'
    train_start: "2020-08-01"
    train_end: "2024-01-01"
    val_end: "2025-01-01"
    test_end: "2026-01-01"
    max_lookback_period: 60
    max_prediction_length: 2
    accelerator: 'cuda'
    devices: 1
    num_workers: 4
    batch_size: 2048
    hidden_size: 17
    attention_head_size: 4
    dropout: 0.16814472086063664
    hidden_continuous_size: 14
    lstm_layers: 1
    learning_rate: 0.0018197008586099835
    max_epochs: 50
    time_frame_unit: 'Day'
    time_frame_amount: 1
    reduce_on_plateau_patience: 2
    gradient_clip_val: 0.4467135116262659
    _best_val_loss: 0.0117
  ubuntu-with-log-return-target-and-all-features:
    notes: ''
    features:
      - open_log_return
      - close
      - high
      - low
      - open
      - trade_count
      - volume
      - vwap
      - day_of_week
      - day_of_month
      - month
      - year
      - surprise
      - is_earnings_day
      - sandp500open
    target: 'open_log_return'
    target_normalizer: 'None'
    train_start: "2020-08-01"
    train_end: "2024-01-01"
    val_end: "2025-01-01"
    test_end: "2026-01-01"
    max_lookback_period: 60
    max_prediction_length: 2
    accelerator: 'cuda'
    devices: 1
    num_workers: 4
    batch_size: 2048
    hidden_size: 17
    attention_head_size: 4
    dropout: 0.16814472086063664
    hidden_continuous_size: 14
    lstm_layers: 1
    learning_rate: 0.0018197008586099835
    max_epochs: 50
    time_frame_unit: 'Day'
    time_frame_amount: 1
    reduce_on_plateau_patience: 2
    gradient_clip_val: 0.4467135116262659
  ubuntu-with-valid-features:
    notes: ''
    features:
      - open_log_return
      - day_of_week
      - day_of_month
      - month
      - year
      - surprise
      - is_earnings_day
      - range
      - body
      - lower_wick
      - upper_wick
    target: 'open_log_return'
    target_normalizer: 'None'
    train_start: "2020-08-01"
    train_end: "2024-01-01"
    val_end: "2025-01-01"
    test_end: "2026-01-01"
    max_lookback_period: 40
    max_prediction_length: 2
    accelerator: 'cuda'
    devices: 1
    num_workers: 4
    batch_size: 2048
    hidden_size: 17
    attention_head_size: 4
    dropout: 0.16814472086063664
    hidden_continuous_size: 14
    lstm_layers: 1
    learning_rate: 0.0018197008586099835
    max_epochs: 50
    time_frame_unit: 'Day'
    time_frame_amount: 1
    reduce_on_plateau_patience: 2
    gradient_clip_val: 0.4467135116262659
  ubuntu-with-close-log-return:
    notes: ''
    features:
      - close_log_return
      - day_of_week
      - day_of_month
      - month
      - year
      - surprise
      - is_earnings_day
      - range
      - body
      - lower_wick
      - upper_wick
    target: 'close_log_return'
    target_normalizer: 'None'
    train_start: "2020-08-01"
    train_end: "2024-01-01"
    val_end: "2025-01-01"
    test_end: "2026-01-01"
    max_lookback_period: 20
    max_prediction_length: 1
    accelerator: 'cuda'
    devices: 1
    num_workers: 4
    batch_size: 2048
    hidden_size: 17
    attention_head_size: 4
    dropout: 0.16814472086063664
    hidden_continuous_size: 14
    lstm_layers: 1
    learning_rate: 0.0018197008586099835
    max_epochs: 50
    time_frame_unit: 'Day'
    time_frame_amount: 1
    reduce_on_plateau_patience: 2
    gradient_clip_val: 0.4467135116262659













